<!DOCTYPE html>
<html lang="en">
<head>
  <script src="script.js"></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Research</title>
  <link rel="stylesheet" href="styles/styles1.css">
</head>
<body>

  <header>
    <nav>
      <ul>
        <li><a href="#overview">Overview</a></li>
        <li><a href="#publications">Publications</a></li>
        <li><a href="#insights">Insights</a></li>
        <li><a href="#inprogress">In Progress</a></li>
        <li><a href="#toread">To Read</a></li>
      </ul>
    </nav>
    <h1><center>AI Research</center></h1>
  </header>

  <main>

    <section id="overview">
      <h2>Overview</h2>
      <img src="assets/1234.jpg">
      <p>Am I an AI research expert...no, have I ever trained a Large language model...I can't afford it...do i have 10+ years experience in Machine Learning...ehm no.</p>
      <p>But I have PASSION, a VISION, AGGRESION *with There is no passion meme voice* plus I believe in just randomly throwing myself into things that I don't know its the best way to learn...well anything, you probably did too once like when you were learning how to walk as a baby. Besides there is no time to learn anything in the entire history of humanity thanks to GPT (Our lord and saviour) so might as well take advantage and just combine Mr Douglas Hofstadter's analysis ( book title : Analogy as the Fuel and Fire of Thinking  (A must read btw)) to learn anything with GPT.</p>
      <img src="assets/55.png">
    </section>

    <section id="publications">
      <h2>Papers</h2>
      <article id="paper1">
        <h3>Improving Factuality and Reasoning in Language Models through Multiagent Debate</h3>
        <img src="paper1.jpg" alt="Research Paper 1">
        <p>More like a group of friends trying to solve a puzzle. Each friend comes up with a piece of the solution. They then discuss their pieces, learn from each other, and adjust their pieces until they all fit together to solve the puzzle. This is what the language models do in the multiagent debate system - they share, learn, and adjust until they agree on the best answer.</p>
        <a href="https://dx.doi.org/10.1145/3511808.3557681">View Full Paper</a>
      </article>
      <article id="paper2">
        <h3>Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees</h3>
        <p>If The ocean represents the high-dimensional space, and your ship is the algorithm trying to find the best route. You could chart your course randomly, but the ocean is vast and full of dangers like storms and reefs (complex problems). Now  if you had an enchanted astrolabe( NEXT algorithm ) that not only maps the stars (problem structures) but also remembers the routes of all past voyages (prior experiences). This astrolabe doesn't just replicate the old routes; it learns from them, understanding which currents were beneficial, where the hidden reefs are, and when storms are likely to occur. It then uses this knowledge to chart the most efficient and safe course through the ocean.</p>
        <a href="https://arxiv.org/pdf/1903.00070v4.pdf">View Full Paper</a>
      </article>

      <article id="paper3">
        <h3>Topology of Learning in Artificial Neural Networks</h3>
        <p>Aight, let's break it down. Imagine you're playing with a bag of marbles, each marble representing a neuron's weight in a neural network. At first, you just dump them on the floor, they scatter randomly, no pattern, no structure. But as you start training the network, it's like you're slowly moving these marbles around, grouping some together, pushing others apart. Over time, you start to see patterns, clusters of marbles here, a line of marbles there. You're not measuring the exact positions, but you're noticing the overall shape they're forming. That's what this paper is doing, but with the weights in a neural network. It's looking at how these weights, these marbles, move around and form patterns as the network learns.</p>
        <a href="https://arxiv.org/pdf/2306.00323.pdf">View Full Paper</a>
      </article>

      <article id="paper4">
        <h3>Forward Thinking: Building Deep Random Forests</h3>
        <p>Forward thinking is deep learning that extends the architectural flexibility and sophisticationof deep neural networks. It allows for different types of learning functions in the network, other than neurons, and the ability to adaptively deepen the network as needed to improve results.</p>
        <a href="https://arxiv.org/pdf/1705.07366.pdf">View Full Paper</a>
      </article>

      <article id="paper5">
        <h3>Textbooks are all you need.</h3>
        <p>So E2E is basically similar to learning to navigate a new city wandering around aimlessly, learning through pure exploration. might be efficient but too consuming. paper proposes a textbook approach like using a well-structured map or GPS, guiding you from point A to B efficiently. The paper argues that in certain scenarios, the map (structured, hierarchical learning) can be more efficient than aimless wandering (end-to-end learning).</p>
        <a href="https://arxiv.org/pdf/2306.11644.pdf">View Full Paper</a>
      </article>

      <!-- Additional publications -->
    </section>

    <section id="insights">
      <h2>Research Insights</h2>
      <article id="insight1">
        <h3>Analogies Explained: Towards Understanding Word Embeddings</h3>
        <p>let's see, so like a mechanic opening up the hood of a car to understand how the engine works. It's dissecting the concept of word embeddings, which are like the gears of a language model, to understand how they interlock and work together to create meaning. It's particularly focused on analogies, which are like the special maneuvers the car can perform. The paper also looks at the errors or the occasional misfires that can occur. It's not just about one type of car, but various models - explicit embeddings, PMI matrix, and Word2Vec. The goal? To fine-tune the engine and make the ride smoother in the world of natural language processing.</p>
        <a href="https://arxiv.org/abs/1801.06146">Read More</a>
      </article>

      <!-- Additional research insights -->
    </section>

    <section id="inprogress">
      <h2>Research In Progress</h2>
      <article id="inprogress1">
        <h3>LongNet: Scaling Transformers to 1,000,000,000 Tokens</h3>
        <img src="inprogress1.jpg" alt="Research In Progress 1">
        <p>LongNet is like a spotlight in a dark room, selectively illuminating only the important parts of a vast space. The 'dilated attention' is the zoom feature of the spotlight, focusing on the details when needed, and pulling back for a broader view when necessary. It's a smart way to navigate a room as large as the internet.</p>
        <a href="https://dx.doi.org/10.1109/IJCNN55064.2022.9892619">Read More</a>
      </article>

     <!-- Additional ongoing research projects -->
    </section>

    <section id="toread">
      <h2>Need to Read</h2>
      <article id="toread1">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread2">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread3">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread4">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread5">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread6">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread7">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread8">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread9">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread10">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread11">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread12">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread13">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread14">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>
      <article id="toread15">
        <h3>Thought cloning: Learning to Think while Acting by Imitating human Thinking</h3>
        <p>In Progress...</p>
      </article>

      <!-- Additional papers to read -->
    </section>

  </main>

  <footer>
    <p>Â© 2023 The Alchemists Odyssey</p>
  </footer>

</body>
</html>
